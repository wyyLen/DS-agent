"""
Example: Using DSAgent Core with MetaGPT

This example demonstrates how to use DSAgent's retrieval and search
mechanisms within a MetaGPT agent.
"""

from pathlib import Path
from dsagent_core.adapters import MetaGPTAdapter
from metagpt.schema import Plan, Task

# Example 1: Text Experience Retrieval
def example_text_retrieval():
    """Example of using text-based experience retrieval"""
    
    # Initialize adapter with text experiences
    adapter = MetaGPTAdapter(
        text_exp_path=Path("examples/data/exp_bank/plan_exp.json")
    )
    
    # Retrieve relevant experiences
    query = "How do I analyze correlation between variables in a dataset?"
    result = adapter.retrieve_text_experiences(query, top_k=3)
    
    print(f"Found {len(result.experiences)} relevant experiences")
    print(f"Retrieval took {result.retrieval_time:.3f} seconds")
    
    for i, exp in enumerate(result.experiences, 1):
        print(f"\nExperience {i} (score: {exp.score:.2f}):")
        print(exp.content[:200] + "...")
    
    # Format for use in prompts
    formatted = adapter.format_experiences_for_prompt(result)
    print("\nFormatted for prompt:")
    print(formatted[:300] + "...")


# Example 2: Workflow Experience Retrieval
def example_workflow_retrieval():
    """Example of using workflow-based experience retrieval"""
    
    # Initialize adapter with workflow experiences
    adapter = MetaGPTAdapter(
        workflow_exp_path=Path("examples/data/exp_bank/workflow_exp2_clean.json")
    )
    
    # Create a sample plan
    plan = Plan()
    plan.add_tasks([
        Task(
            task_id="1",
            instruction="Load and inspect the dataset",
            task_type="pda",
            dependent_task_ids=[]
        ),
        Task(
            task_id="2",
            instruction="Calculate correlation between features",
            task_type="correlation analysis",
            dependent_task_ids=["1"]
        ),
        Task(
            task_id="3",
            instruction="Visualize correlations",
            task_type="visualization",
            dependent_task_ids=["2"]
        )
    ])
    
    # Retrieve similar workflows
    result = adapter.retrieve_workflow_experiences(plan, top_k=3)
    
    print(f"Found {len(result.experiences)} similar workflows")
    
    for i, exp in enumerate(result.experiences, 1):
        print(f"\nWorkflow {i} (similarity: {exp.score:.2f}):")
        print(f"  Tasks: {exp.metadata.get('num_tasks', 0)}")
        print(f"  Types: {', '.join(exp.metadata.get('task_types', []))}")


# Example 3: Combined Retrieval in Agent
def example_combined_retrieval():
    """Example of using both retrieval methods together"""
    
    # Initialize adapter with both types of experiences
    adapter = MetaGPTAdapter(
        text_exp_path=Path("examples/data/exp_bank/plan_exp.json"),
        workflow_exp_path=Path("examples/data/exp_bank/workflow_exp2_clean.json")
    )
    
    # User query
    user_query = "Analyze the relationship between features and predict target variable"
    
    # Step 1: Retrieve relevant text experiences
    text_result = adapter.retrieve_text_experiences(user_query, top_k=2)
    print("Text Experiences Retrieved:")
    for exp in text_result.experiences:
        print(f"  - Score {exp.score:.2f}: {exp.content[:80]}...")
    
    # Step 2: Create a plan (could be generated by planning action)
    plan = Plan()
    plan.add_tasks([
        Task(task_id="1", instruction="Load data", task_type="pda", dependent_task_ids=[]),
        Task(task_id="2", instruction="Feature analysis", task_type="statistical analysis", dependent_task_ids=["1"]),
        Task(task_id="3", instruction="Build model", task_type="machine learning", dependent_task_ids=["2"])
    ])
    
    # Step 3: Retrieve similar workflows
    workflow_result = adapter.retrieve_workflow_experiences(plan, top_k=2)
    print("\nWorkflow Experiences Retrieved:")
    for exp in workflow_result.experiences:
        print(f"  - Similarity {exp.score:.2f}: {exp.metadata.get('num_tasks', 0)} tasks")
    
    # Step 4: Combine insights
    print("\nCombined insights can guide the agent's planning and execution...")


# Example 4: Tree Search for Exploration
def example_tree_search():
    """Example of using tree search for autonomous exploration"""
    
    from dsagent_core.search import TreeSearchEngine, ActionGenerator, StateEvaluator, TerminationChecker
    
    # Simple example implementations
    class SimpleActionGenerator(ActionGenerator):
        def generate_actions(self, state, context):
            # Generate possible next steps
            if isinstance(state, str) and state == "start":
                return ["explore_data", "check_schema", "visualize"]
            elif state == "explore_data":
                return ["analyze_distributions", "find_correlations"]
            return []
    
    class SimpleEvaluator(StateEvaluator):
        def evaluate(self, state, context):
            # Simple heuristic evaluation
            scores = {
                "explore_data": 0.8,
                "check_schema": 0.6,
                "analyze_distributions": 0.9,
                "find_correlations": 0.85
            }
            return scores.get(state, 0.5)
    
    class SimpleTerminationChecker(TerminationChecker):
        def is_terminal(self, state, context):
            terminal_states = ["analyze_distributions", "find_correlations"]
            return state in terminal_states
    
    # Create tree search engine
    adapter = MetaGPTAdapter()
    engine = adapter.create_tree_search_engine(
        action_generator=SimpleActionGenerator(),
        state_evaluator=SimpleEvaluator(),
        termination_checker=SimpleTerminationChecker(),
        max_depth=3,
        max_iterations=10
    )
    
    # Perform search
    root = engine.search(initial_state="start")
    
    # Get best path
    best_path = engine.get_best_path(root)
    print("Best exploration path:")
    for i, node in enumerate(best_path):
        print(f"  Step {i}: {node.state} (value: {node.value:.2f}, visits: {node.visits})")
    
    # Get statistics
    stats = engine.get_statistics(root)
    print(f"\nSearch Statistics:")
    print(f"  Total nodes explored: {stats['total_nodes']}")
    print(f"  Max depth reached: {stats['max_depth_reached']}")


# Example 5: Adding New Experiences
def example_add_experience():
    """Example of adding new experiences to the knowledge base"""
    
    from dsagent_core.retrieval.base import ExperienceEntry
    
    adapter = MetaGPTAdapter(
        text_exp_path=Path("examples/data/exp_bank/plan_exp.json")
    )
    
    # Add a new experience
    new_exp = ExperienceEntry(
        content="To handle missing values, use df.fillna() or df.dropna() based on the data characteristics.",
        metadata={"task_type": "data_preprocessing", "domain": "pandas"}
    )
    
    success = adapter.text_retriever.add_experience(new_exp)
    print(f"Added new experience: {success}")
    
    # Save updated experiences
    # adapter.text_retriever.save_experiences(Path("updated_exp.json"))


if __name__ == "__main__":
    print("=== Example 1: Text Experience Retrieval ===")
    example_text_retrieval()
    
    print("\n\n=== Example 2: Workflow Experience Retrieval ===")
    example_workflow_retrieval()
    
    print("\n\n=== Example 3: Combined Retrieval ===")
    example_combined_retrieval()
    
    print("\n\n=== Example 4: Tree Search ===")
    example_tree_search()
    
    print("\n\n=== Example 5: Adding Experiences ===")
    example_add_experience()
